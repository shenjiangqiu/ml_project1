{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitb60bbb78f313426aaff905d05565e3d2",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def process_input(input,poly_degree):\n",
    "    phi=input\n",
    "    new_phi=phi\n",
    "    for i in range(2,poly_degree+1): # append x^2, x^3 ... to the tail\n",
    "        new_phi=np.append(new_phi,phi**i,axis=1)\n",
    "    phi=new_phi\n",
    "    #print(\"phi:\\n\",phi)\n",
    "    ones=np.ones((input.shape[0],1))\n",
    "    phi=np.append(ones,phi,axis=1)\n",
    "    return phi\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_regression(trainX,testX,noutputs):\n",
    "    ## coding herexs\n",
    "    #print(trainX.shape)\n",
    "    #print(testX.shape)\n",
    "    #print(noutputs)\n",
    "    phi=None\n",
    "    phi=trainX[:,0:trainX.shape[1]-noutputs]\n",
    "    T=trainX[:,trainX.shape[1]-noutputs:]\n",
    "\n",
    "    # try different model \n",
    "    poly_degree=(1,2,3,4,5,6) # 1 for linear model,2~6 for poly model\n",
    "    m_lambda=(0,0.001,0.01,0.1,1,10,100) # 0 for no regular, \n",
    "\n",
    "    # using different method to build the input for different modle\n",
    "    models_map=dict() # record all the models and cv loss\n",
    "    for t_poly in poly_degree: # test every poly degree\n",
    "        #print(\"degree = %d\"%(t_poly))\n",
    "        phi=trainX[:,0:trainX.shape[1]-noutputs]\n",
    "        phi=process_input(phi,t_poly) #add degree and add bias\n",
    "        for t_lambda in m_lambda: #test every lambda for\n",
    "            #print(\"lmbda=\",t_lambda)\n",
    "            cv=np.array([])\n",
    "            for cross_valid in range(5):# cross validation\n",
    "                total=len(phi)\n",
    "                start=int(total*cross_valid/5)\n",
    "                end=int(total*(cross_valid+1)/5)\n",
    "                if start==end:\n",
    "                    end=end+1\n",
    "                test_case=phi[start:end]\n",
    "                train_case=np.append(phi[0:start],phi[end:],axis=0)\n",
    "                test_T=T[start:end]\n",
    "                train_T=np.append(T[0:start],T[end:],axis=0)\n",
    "                #print(\"test_case\",test_case)\n",
    "                #print(\"train_case\",train_case)\n",
    "                #print(\"test_T=\",test_T)\n",
    "                #print(\"train_T=\",train_T)\n",
    "                \n",
    "\n",
    "                W=np.dot(np.dot(np.linalg.inv( t_lambda * np.eye(train_case.shape[1]) + np.dot(train_case.T,train_case)),train_case.T),train_T)\n",
    "                #print(\"W=\",W)\n",
    "                #print(\"train_out=\",np.dot(train_case,W))\n",
    "                test_out=np.dot(test_case,W)\n",
    "                #print(test_out)\n",
    "                t_loss=np.average((test_out-test_T)**2)\n",
    "                #print(\"t_loss=\",t_loss)\n",
    "                cv=np.append(cv,t_loss)\n",
    "            #print(cv)# the cv \n",
    "            models_map[(t_poly,t_lambda)]=np.average(cv)\n",
    "    #print(models_map)\n",
    "    min=float(\"inf\")\n",
    "    min_model=0\n",
    "    #print(models_map)\n",
    "    for model in models_map:\n",
    "        if models_map[model]<min:\n",
    "            min=models_map[model]\n",
    "            min_model=model\n",
    "    \n",
    "    #print(min_model)\n",
    "    #print(min)\n",
    "    t_poly,t_lambda=min_model\n",
    "\n",
    "    # train the whole trainning set\n",
    "    phi=trainX[:,0:trainX.shape[1]-noutputs]\n",
    "    phi=process_input(phi,t_poly)\n",
    "    \n",
    "\n",
    "    W=np.dot(np.dot(np.linalg.inv( t_lambda * np.eye(phi.shape[1]) + np.dot(phi.T,phi)),phi.T),T)\n",
    "    #print(testX)\n",
    "    testX=process_input(testX,t_poly)\n",
    "    #print(testX)\n",
    "    return np.dot(testX,W)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##main:\n",
    "\n",
    "#trainX=np.array([[1,2,4],[4,21,29],[5,10,20],[2,3,7],[8,100,116],[3,4,10],[9,100,118]])\n",
    "def fx(x,y):\n",
    "    return x**3+y**2\n",
    "x=[1,4,9,11,23,44,98,91,49,29,87]\n",
    "y=[5,9,18,13,22,19,100,2,19,11,23]\n",
    "tx=[22,33,44,55]\n",
    "ty=[11,33,12,42]\n",
    "\n",
    "trainX=np.array([])\n",
    "for i in range(len(x)):\n",
    "    trainX=np.append(trainX,[[x[i],y[i],fx(x[i],y[i])]])\n",
    "trainX=trainX.reshape(-1,3)\n",
    "\n",
    "testX=np.array([])\n",
    "\n",
    "for i in range(len(tx)):\n",
    "    testX=np.append(testX,[[tx[i],ty[i]]])\n",
    "testX=testX.reshape(-1,2)\n",
    "#print(trainX)\n",
    "#print(testX)\n",
    "#trainX=np.array([[1,2,4],[4,21,29],[5,10,20],[2,3,7],[8,100,116],[3,4,10],[9,100,118]])\n",
    "#testX=np.array([[1,1],[2,2],[3,3]])\n",
    "\n",
    "testOut=my_regression(trainX,testX,1)\n",
    "#print(testOut)\n",
    "#print([fx(x,y) for x,y in zip(tx,ty) ])\n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"./airfoil_self_noise.dat\"\n",
    "inputs=[]\n",
    "with open(data) as f:\n",
    "    for line in iter(f.readline,''):\n",
    "        inputs.append(line.split())\n",
    "inputs=np.array(inputs)\n",
    "trainX=inputs[0:-1]\n",
    "testX=inputs[-1:]\n",
    "print(trainX.shape)\n",
    "print(testX.shape)\n",
    "print(testX)\n",
    "usingRegularizer=False\n",
    "testOut=my_regression(trainX,testX[:,0:-1],1)\n",
    "print(testOut)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}